{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"FoodOrderDelivery\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------------+-----------+---------------+-----------------+-------------------+\n",
      "|source_zip|order_id|         order_time|order_value|destination_zip|deliveryPerson_id|      delivery_time|\n",
      "+----------+--------+-------------------+-----------+---------------+-----------------+-------------------+\n",
      "|     65009| 729-975|2018-08-09 18:32:18|        592|          75415|              420|2018-08-11 06:54:19|\n",
      "|     58603| 366-147|2018-08-09 01:17:32|        077|          44332|              175|2018-08-11 12:12:25|\n",
      "|     80669| 451-711|2018-08-09 05:46:17|        383|          66459|              932|2018-08-11 11:39:03|\n",
      "|     81133| 180-810|2018-08-09 03:37:44|        801|          81045|              527|2018-08-11 11:22:14|\n",
      "|     62615| 385-628|2018-08-09 19:04:27|        361|          24615|              827|2018-08-11 06:22:26|\n",
      "|     89569| 080-189|2018-08-09 17:26:35|        784|          48874|              247|2018-08-11 01:14:42|\n",
      "|     09868| 113-542|2018-08-09 18:19:19|        259|          97946|              183|2018-08-11 23:23:24|\n",
      "|     99672| 353-342|2018-08-09 22:53:55|        116|          99874|              778|2018-08-11 10:22:42|\n",
      "|     78576| 509-761|2018-08-09 22:16:43|        547|          81972|              477|2018-08-11 17:40:13|\n",
      "|     93595| 921-693|2018-08-09 20:17:19|        186|          87651|              147|2018-08-11 05:04:49|\n",
      "|     35974| 836-589|2018-08-09 06:31:33|        100|          11759|              975|2018-08-11 04:55:00|\n",
      "|     48547| 878-471|2018-08-09 15:33:22|        124|          94615|              280|2018-08-11 08:52:11|\n",
      "|     84502| 378-364|2018-08-09 23:25:24|        969|          91397|              816|2018-08-11 04:59:14|\n",
      "|     78851| 072-782|2018-08-09 03:22:04|        269|          63920|              504|2018-08-11 19:08:46|\n",
      "|     25289| 072-131|2018-08-09 20:43:31|        818|          34599|              501|2018-08-11 20:40:44|\n",
      "|     67002| 258-303|2018-08-09 19:30:47|        680|          33781|              082|2018-08-11 19:58:25|\n",
      "|     81523| 244-439|2018-08-09 22:46:44|        602|          57786|              439|2018-08-11 14:37:10|\n",
      "|     25307| 900-755|2018-08-09 15:49:21|        005|          45143|              497|2018-08-11 04:32:42|\n",
      "|     74741| 754-493|2018-08-09 14:28:03|        236|          57955|              027|2018-08-11 10:49:00|\n",
      "|     46945| 248-869|2018-08-09 09:00:55|        610|          54794|              728|2018-08-11 08:01:33|\n",
      "+----------+--------+-------------------+-----------+---------------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"orders\", StringType())\n",
    "])\n",
    "\n",
    "ordersDF = spark.read.csv('/datacartridge/streamData/foodDelivery/Raw/delTimeAssigned/*.csv', header=True, schema=schema)\n",
    "\n",
    "#ordersDF.show(10)\n",
    "\n",
    "finalDF=ordersDF.withColumn('source_zip',f.split('orders',',')[0])\\\n",
    "                .withColumn('order_id',f.split('orders',',')[1])\\\n",
    "                .withColumn('order_time',f.split('orders',',')[2])\\\n",
    "                .withColumn('order_value',f.split('orders',',')[3])\\\n",
    "                .withColumn('destination_zip',f.split('orders',',')[4])\\\n",
    "                .withColumn('deliveryPerson_id',f.split('orders',',')[5])\\\n",
    "                .withColumn('delivery_time',f.split('orders',',')[6]).drop('orders')#.show()\n",
    "                \n",
    "timeFmt = \"yyyy-MM-dd HH:mm:ss\"\n",
    "timeDiff = (f.unix_timestamp('delivery_time', format=timeFmt) - f.unix_timestamp('order_time', format=timeFmt))\n",
    "\n",
    "finalDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 from_zip_code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|destination_zip|count|\n",
      "+---------------+-----+\n",
      "|          31487|    4|\n",
      "|          55458|    4|\n",
      "|          43896|    4|\n",
      "|          92407|    4|\n",
      "|          79111|    4|\n",
      "|          43462|    3|\n",
      "|          81194|    3|\n",
      "|          84316|    3|\n",
      "|          86278|    3|\n",
      "|          44954|    3|\n",
      "|          13447|    3|\n",
      "|          39167|    3|\n",
      "|          28180|    3|\n",
      "|          36884|    3|\n",
      "|          92929|    3|\n",
      "|          68012|    3|\n",
      "|          24155|    3|\n",
      "|          53401|    3|\n",
      "|          89128|    3|\n",
      "|          38798|    3|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalDF.groupby(\"destination_zip\").count().sort(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total value of orders that are in order_delivered per delivery person**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+\n",
      "|deliveryPerson_id|sum(order_value)|\n",
      "+-----------------+----------------+\n",
      "|              829|          8267.0|\n",
      "|              296|         18893.0|\n",
      "|              675|         10118.0|\n",
      "|              691|         13406.0|\n",
      "|              467|          5848.0|\n",
      "|              451|          9912.0|\n",
      "|              125|         12686.0|\n",
      "|              853|          8795.0|\n",
      "|              800|          9433.0|\n",
      "|              944|         14673.0|\n",
      "|              919|          9343.0|\n",
      "|              870|          6445.0|\n",
      "|              666|          7392.0|\n",
      "|              926|          8304.0|\n",
      "|              124|         12417.0|\n",
      "|              591|          8612.0|\n",
      "|              447|         10443.0|\n",
      "|              718|         10368.0|\n",
      "|              574|          7872.0|\n",
      "|              307|         10997.0|\n",
      "+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalDF.groupBy(\"deliveryPerson_id\").agg(f.sum(\"order_value\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average delivery time for delivered orders per delivery person**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|deliveryPerson_id|     avg(Duration)|\n",
      "+-----------------+------------------+\n",
      "|              829| 49.43887037037037|\n",
      "|              296| 47.68906862745097|\n",
      "|              675|47.938225308641975|\n",
      "|              467| 48.07998015873016|\n",
      "|              691| 50.47842171717173|\n",
      "|              451| 49.76264619883041|\n",
      "|              125| 45.95642361111111|\n",
      "|              853| 49.86302469135804|\n",
      "|              944| 51.70226666666667|\n",
      "|              800|51.352048611111115|\n",
      "|              919|48.333763888888896|\n",
      "|              870| 44.31285185185185|\n",
      "|              666|46.334357638888896|\n",
      "|              926| 47.58458333333334|\n",
      "|              124| 49.59237268518519|\n",
      "|              591|45.816765873015875|\n",
      "|              447| 48.40842995169083|\n",
      "|              574| 44.45122222222222|\n",
      "|              475| 46.74936213991769|\n",
      "|              613| 46.73893518518518|\n",
      "+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "durationDF=finalDF.withColumn(\"Duration\", timeDiff/3600)#.show()\n",
    "\n",
    "durationDF.groupBy(\"deliveryPerson_id\").agg(f.avg(\"Duration\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 2.1.0)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
